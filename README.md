# ML_Learn
## LR 1
### Функции

Аналитическое решение
функция растригина:
- best x: 0 0
- best f(x): 0

Функция Стыбинского-Танга:
- best x: -2.9 -2.9
- best f(x): ~ (39 * 2)

![Функции](https://github.com/FastSnake0/ML_learn/blob/main/refs/funcs.png)

### GD

функция растригина:
- best x: 2.10159495e-09 -9.94958638e-01 
- best f(x): 9.94959057e-01

Функция Стыбинского-Танга:
- best x: 2.74680274   2.74680277
- best f(x): -50.05889331

![Обычный gd](https://github.com/FastSnake0/ML_learn/blob/main/refs/gd.png)

### Momentum GD

функция растригина:
- best x:  2.10159495e-09 -9.94958638e-01 
- best f(x): 9.94959057e-01

Функция Стыбинского-Танга:
- best x: -2.90353403   2.74680274
- best f(x): -64.19561236

![Обычный gd](https://github.com/FastSnake0/ML_learn/blob/main/refs/mgd.png)

### ADAM

функция растригина:
- best x: 5.75425118e-12 9.94958636e-01 
- best f(x): 9.94959057e-01

Функция Стыбинского-Танга:
- best x: -2.90353403  -2.903534  
- best f(x): -78.33233141

![Обычный gd](https://github.com/FastSnake0/ML_learn/blob/main/refs/adam.png)

## LR 2
### Алгоритмы
Differential Evolution:
Основан на идеях эволюционных стратегий. Использует популяцию векторов параметров и проводит операции мутации, кроссовера и селекции для поиска оптимальных параметров. Мутации производятся путем комбинирования различных индивидов в популяции.

Particle Swarm Optimization:
Моделирует поведение роя частиц в пространстве параметров. Каждая частица движется по пространству, обновляя свое положение в зависимости от своей лучшей позиции и лучшей позиции в рое. Таким образом, алгоритм старается найти оптимальное положение в пространстве параметров.

Self-Adaptive Differential Evolution:

Расширение Differential Evolution с механизмом автоматической настройки параметров мутации. Позволяет алгоритму самостоятельно адаптироваться к характеру задачи оптимизации в процессе выполнения.

### Таблица сравнений

First Header  | Second Header
------------- | -------------
Content Cell  | Content Cell
Content Cell  | Content Cell
